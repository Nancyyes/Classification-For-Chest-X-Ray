{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# CNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator ## NN \nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator ## NN \nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#clone the dataset from the github repository\n! git clone https://github.com/education454/datasets.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set the path to the main dir\nimport os \nmain_dir = \"./datasets/Data\"\n#set the path to the train dir\ntrain_dir = os.path.join(main_dir, \"train\")\n#set the path to the test dir\ntest_dir = os.path.join(main_dir, \"test\")\n#directory with the training covid images\ntrain_covid_dir = os.path.join(train_dir, \"COVID19\")\n#directory with the training normal images\ntrain_normal_dir = os.path.join(train_dir, \"NORMAL\")\n#directory with the testing covid images\ntest_covid_dir = os.path.join(test_dir, \"COVID19\")\n#directory with the testing normal images\ntest_normal_dir = os.path.join(test_dir, \"NORMAL\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the filenames\ntrain_covid_name  = os.listdir(train_covid_dir)\nprint(train_covid_name[:10])\n\ntrain_normal_name  = os.listdir(train_normal_dir)\nprint(train_normal_name[:10])\n\ntest_covid_name  = os.listdir(test_covid_dir)\nprint(test_covid_name[:10])\n\ntest_normal_name  = os.listdir(test_normal_dir)\nprint(test_normal_name[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print the total no of images present in each dir\nprint(\"Total Images Present in The training Set: \", len(train_covid_name+train_normal_name))\nprint(\"Total Images Present in The testing Set: \", len(test_covid_name+test_normal_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TASK 3 : Data Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot a grid of 16 images (8 images of Covid19 and 8 images of Normal)\nimport matplotlib.image as mpimg\n#set the number of columns and rows\nrows = 4\ncols = 4\n\n#set the figure size\nfig = plt.gcf()\nfig.set_size_inches(12,12)\n#get the filenames from the covid & normal dir of the train dataset\ncovid_pic = [os.path.join(train_covid_dir, filename)for filename in train_covid_name[0:8]]\nnormal_pic = [os.path.join(train_normal_dir, filename)for filename in train_normal_name[0:8]] ## find the name with its coressponding pic\n#print the list\nprint(covid_pic)\nprint(normal_pic)\n#merge the covid and normal list\nmerged_list = covid_pic + normal_pic\nfor i, img_path in enumerate(merged_list):\n  data = img_path.split(\"/\", 6)[5] # only want the last 6 digits of name\n  sp = plt.subplot(rows, cols, i + 1)\n  sp.axis(\"off\")\n  img = mpimg.imread(img_path)\n  sp.set_title(data, fontsize = 10)\n  plt.imshow(img, cmap = \"gray\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"TASK 4 : Data Preprocessing & Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate training,testing and validation batches \n# generate training,testing and validation batches \ndgen_train =  ImageDataGenerator(rescale = 1./255,\n                                validation_split = 0.2,\n                                zoom_range = 0.2,\n                                horizontal_flip = True) # normalized by rescale, zoom = randome cross from the image, horizontal  \ndgen_validation = ImageDataGenerator(rescale = 1./255)\ndgen_test =  ImageDataGenerator(rescale = 1./255)\n\ntrain_generator = dgen_train.flow_from_directory(train_dir,\n                                                                            target_size = (150, 150),\n                                                                            subset = \"training\",\n                                                                            batch_size = 32,\n                                                                            class_mode = \"binary\") #invoke flow # l image from the train directory, size here is the size we want the image tobe , batch == how mamy images will be sized in a once, class mode is k classees\n\nvalidation_generator  =dgen_train.flow_from_directory(train_dir, target_size = (150,150),\n                                                                            subset = \"validation\",\n                                                                            batch_size = 32,\n                                                                            class_mode = \"binary\" \n)\n\ntest_generator = dgen_train.flow_from_directory(test_dir, target_size = (150,150),\n\n                                                                            batch_size = 32,\n                                                                            class_mode = \"binary\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Task 5 CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n# add the convolutional layer\n# filters, size of filters,padding,activation_function,input_shape\nmodel.add(Conv2D(32, (5,5), padding=\"SAME\", activation=\"relu\", input_shape = (150,150,3))) # the shape should be the same with above \nmodel.add(MaxPooling2D(pool_size=(2,2))) # reduce the szie to half to reduce the parameters\n# place a dropout layer to avoide overfitting \nmodel.add(Dropout(0.5)) # drop out 50% neuros to \n# add another convolutional layer \nmodel.add(Conv2D(64, (5,5), padding=\"SAME\", activation=\"relu\"))\n# pooling layer\nmodel.add(MaxPooling2D(pool_size=(2,2))) # have is 32\n# place a dropout layer\nmodel.add(Dropout(0.5)) # half is 16\n# Flatten layer covert the 2D image to 1D image \nmodel.add(Flatten())\n# add a dense layer : amount of nodes, activation ## all neuros are connected to the next layer 16*16\nmodel.add(Dense(256, activation=\"relu\"))\n# place a dropout layer\n# 0.5 drop out rate is recommended, half input nodes will be dropped at each update, output layer here only 1 layer \nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation= \"sigmoid\"))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Analysis for the above\nThe first LayerL The output is from (150,150,3) to (150, 150, 32) BECAUSE: (32, (5,5)) with 32 filters\n\nmax_pooling2d (2,2) for becoming two windows, then shape become (75,75,32) \n\nconv2d_1 (Conv2D)            (None, 75, 75, 64)  # second layer uses 64 filters\n\nmax_pooling2d_1 (MaxPooling2 (None, 37, 37, 64) # become two windos, then half \n\noutput layer with one output dense_1 (Dense)              (None, 1)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TASK 6 : Compile & Train the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#compile the model\nmodel.compile(Adam(lr = 0.001), loss = \"binary_crossentropy\", metrics= [\"accuracy\"]) # training rate = 0.001, metrics == track of -- for each epoch ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the model\n# 30 epoches, 30 times to pass the whole data to network\nhistory = model.fit(train_generator,\n                    epochs = 5,\n                    validation_data = validation_generator) ## what is the difference between epos and batches: 10000 images, batch = 10 which means that 10 images one group to pass the network, and it takes 100 time to make all the data to pass the one single epos","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TASK 7 : Performance Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#get the keys of history object\n# 30 epoches, 30 times to pass the whole data to network\nhistory.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot graph between training and validation loss\nplt.plot(history,history[\"loss\"])\nplt.plot(history.history['val_loss'])\nplt.legend([\"Training\", \"Validation\"])\nplt.title(\"Training and validation Lossess\")\nplt.xlabel(\"epoch\") # loss going down, is good! ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot graph between training and validation accuarcy\nplt.plot(history,history[\"accuracy\"])\nplt.plot(history.history['val_accuracy'])\nplt.legend([\"Training\", \"Validation\"])\nplt.title(\"Training and validation accuracy\")\nplt.xlabel(\"epoch\") # accuracy is going up, great!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the test acuarcy and loss\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(\"test loss: {} test acc: {}\".format(test_loss, test_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TASK 8 : Prediction On New Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from google.colab import files\nfrom keras.preprocessing import image\nuploaded = files.upload()\nfor filename in uploaded.keys():\n  img_path = \"/content/\" + filename\n  imges = image.load_img(img_path, target_size = (150,150))\n  images = np.expand_dims(images, axis = 0)\n  predicition = model.predict(images)\n  ## 1 for covide, 0 for non\n  print(filename)\n\n  if prediction == 0:\n    print(\"covide detected\")\n  else:\n    print(\"Your report is normal\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import necessary packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\nimport seaborn as sns\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read csv file containing training datadata\ntrain_df = pd.read_csv(\"nih/train-small.csv\")\n# Print first 5 rows\nprint(f'There are {train_df.shape[0]} rows and {train_df.shape[1]} columns in this data frame')\ntrain_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}